import requests
import platform
from bs4 import BeautifulSoup
from urllib.parse import urlparse, parse_qs, urljoin
import socket
import nmap
from requests.exceptions import RequestException, ConnectTimeout
from rich.console import Console
from rich.table import Table
from rich.progress import Progress, BarColumn, TextColumn
import re
import time
import os

# Configure logging to suppress messages
import logging
logging.basicConfig(level=logging.CRITICAL, format='%(asctime)s - %(levelname)s - %(message)s')

console = Console()

def clear_screen():
    """
    Clear the terminal screen for both Windows and Linux/MacOS.
    """
    if platform.system().lower() == "windows":
        os.system('cls')
    else:
        os.system('clear')

def generate_html_report(vulnerabilities, info, crawled_data):
    """
    Generate an HTML report from the vulnerability scan results.

    Args:
        vulnerabilities (list): List of vulnerability findings.
        info (dict): Information about the target gathered during the scan.
        crawled_data (list): Data collected during the website crawling.
    """
    html_content = f"""
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Laporan Pengujian Keamanan Web</title>
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">
        <style>
            body {{ padding: 20px; }}
            table {{ width: 100%; }}
            th, td {{ text-align: center; }}
            .alert {{ margin-bottom: 0; }}
        </style>
    </head>
    <body>
        <div class="container">
            <h1>Laporan Pengujian Keamanan Web</h1>
            <h2>Informasi Target</h2>
            <ul>
                <li><strong>Alamat IP:</strong> {info['Alamat IP']}</li>
                <li><strong>Port Terbuka:</strong> {', '.join(map(str, info['Port Terbuka']))}</li>
                <li><strong>Header:</strong> {info['Header']}</li>
            </ul>

            <h2>Data yang Dirayapi</h2>
            <ul>
                {''.join(f"<li>{entry['url']} - {entry.get('details', '')}</li>" for entry in crawled_data)}
            </ul>

            <h2>Temuan Kerentanan</h2>
            <table class="table table-striped">
                <thead>
                    <tr>
                        <th>URL</th>
                        <th>Parameter</th>
                        <th>Payload</th>
                        <th>Response Code</th>
                        <th>Severity</th>
                        <th>Details</th>
                    </tr>
                </thead>
                <tbody>
                    {''.join(f"<tr><td>{v['URL']}</td><td>{v['Parameter']}</td><td>{v['Payload']}</td><td>{v['Response Code']}</td><td>{v['Severity']}</td><td>{v['Details']}</td></tr>" for v in vulnerabilities)}
                </tbody>
            </table>
        </div>
        <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.5.2/dist/umd/popper.min.js"></script>
        <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"></script>
    </body>
    </html>
    """
    with open("report.html", "w") as file:
        file.write(html_content)
    console.print("[bold green]Laporan HTML telah dibuat: report.html[/bold green]")

def request_with_retry(url, method='GET', max_retries=3, timeout=5, **kwargs):
    """
    Perform an HTTP request with retries in case of failure.

    Args:
        url (str): The URL to request.
        method (str): HTTP method to use.
        max_retries (int): Maximum number of retry attempts.
        timeout (int): Timeout duration for each request.
        **kwargs: Additional arguments for the request.

    Returns:
        requests.Response or None: The HTTP response if successful, otherwise None.
    """
    for attempt in range(max_retries):
        try:
            response = requests.request(method, url, timeout=timeout, **kwargs)
            response.raise_for_status()
            return response
        except (ConnectTimeout, RequestException):
            if attempt < max_retries - 1:
                time.sleep(1)  # Wait before retrying
            else:
                return None

def detect_waf(url):
    """
    Detect the presence of a Web Application Firewall (WAF) on the target URL.

    Args:
        url (str): The URL to check for WAF presence.

    Returns:
        str or None: The name of the detected WAF or None if no WAF is detected.
    """
    waf_patterns = {
        'Cloudflare': 'cf-ray',
        'AWS WAF': 'x-amzn-waf',
        'ModSecurity': 'modsecurity',
        'Sucuri': 'x-sucuri-id',
    }
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    response = request_with_retry(url, headers=headers)
    if response:
        for waf, pattern in waf_patterns.items():
            if pattern.lower() in response.headers:
                return waf
    return None

def gather_info(target_url):
    """
    Gather information about the target URL including IP address, open ports, and HTTP headers.

    Args:
        target_url (str): The target URL to gather information from.

    Returns:
        dict: A dictionary containing the IP address, open ports, and HTTP headers of the target.
    """
    if not target_url.startswith(('http://', 'https://')):
        target_url = "http://" + target_url

    parsed_url = urlparse(target_url)
    ip_address = socket.gethostbyname(parsed_url.hostname)

    # Port Scanning
    scanner = nmap.PortScanner()
    open_ports = []
    try:
        scanner.scan(ip_address, '1-1024')
        open_ports = [port for port in scanner[ip_address]['tcp'] if scanner[ip_address]['tcp'][port]['state'] == 'open']
    except Exception:
        pass  # Suppress port scanning error

    # Get headers
    response = request_with_retry(target_url)
    headers = response.headers if response else "Tidak ada respons yang diterima."

    return {
        "Alamat IP": ip_address,
        "Port Terbuka": open_ports,
        "Header": headers,
    }

def crawl_website(start_url):
    """
    Crawl the website to extract URLs, parameters, and detect sensitive files.

    Args:
        start_url (str): The starting URL for the crawl.

    Returns:
        list: A list of dictionaries containing crawled URLs, parameters, and additional details.
    """
    urls_to_visit = {start_url}
    visited_urls = set()
    crawled_data = []

    sensitive_file_patterns = [
        r'\.env$', r'\.git$', r'\.htaccess$', r'config\.php$', r'backup$', r'database$', r'\.bak$', r'\.sql$',
        r'\.log$', r'\.json$', r'\.yaml$', r'config\.js$', r'\.old$', r'\.inc$', r'web\.config$', r'wp-config$'
    ]

    with Progress(
        TextColumn("[bold cyan]Merayapi Situs Web dan Ekstraksi Parameter...[/bold cyan]"),
        BarColumn(),
        "[progress.percentage]{task.percentage:>3.0f}%",
        transient=True
    ) as progress:
        task = progress.add_task("[cyan]Memproses...", total=len(urls_to_visit))

        while urls_to_visit:
            url = urls_to_visit.pop()
            if url in visited_urls:
                continue

            visited_urls.add(url)
            response = request_with_retry(url)
            if response is None or not response.text.strip():
                continue

            soup = BeautifulSoup(response.text, 'html.parser')
            domain = urlparse(url).netloc
            params = {}

            # Extract query parameters
            query_params = parse_qs(urlparse(url).query)
            if query_params:
                params.update(query_params)

            # Extract links
            for link in soup.find_all('a', href=True):
                full_url = urljoin(url, link['href'])
                if urlparse(full_url).netloc == domain and full_url not in visited_urls:
                    urls_to_visit.add(full_url)
                    if any(re.search(pattern, full_url, re.IGNORECASE) for pattern in sensitive_file_patterns):
                        crawled_data.append({'url': full_url, 'details': 'Potensi file atau folder sensitif'})

            # Extract forms
            for form in soup.find_all('form'):
                action = form.get('action')
                method = form.get('method', 'GET').upper()
                inputs = form.find_all('input')
                form_params = {}
                for input_tag in inputs:
                    name = input_tag.get('name')
                    if name:
                        form_params[name] = input_tag.get('value', '')

                form_action_url = urljoin(url, action) if action else url
                crawled_data.append({'url': form_action_url, 'params': form_params, 'method': method})

            crawled_data.append({'url': url, 'params': params})
            progress.update(task, advance=1)
            time.sleep(0.1)  # Simulate processing time

    return crawled_data

def test_vulnerabilities(crawled_data):
    """
    Execute vulnerability tests on the crawled data.

    Args:
        crawled_data (list): List of crawled data containing URLs and parameters.

    Returns:
        list: List of detected vulnerabilities.
    """
    vulnerabilities = []

    # Detect WAF
    detected_waf = detect_waf(crawled_data[0]['url'])
    if detected_waf:
        console.print(f"[bold yellow]WAF terdeteksi: {detected_waf}[/bold yellow]")

    # List of test functions
    test_functions = [
        test_directory_traversal,
        test_sensitive_data_exposure,
        test_sql_injection,
        test_xss,
        test_bruteforce,
        test_file_inclusion,
        test_csrf,
        test_file_upload
    ]

    with Progress(
        TextColumn("[bold cyan]Mengujinya... {task.description}[/bold cyan]"),
        BarColumn(),
        "[progress.percentage]{task.percentage:>3.0f}%",
        transient=True
    ) as progress:
        for test_func in test_functions:
            task = progress.add_task(f"[cyan]{test_func.__name__.replace('_', ' ').title()}[/cyan]", total=len(crawled_data))
            for data in crawled_data:
                result = test_func(data)
                if result:
                    vulnerabilities.extend(result)
                progress.update(task, advance=1)
                time.sleep(0.1)  # Simulate processing time

    return vulnerabilities

def test_directory_traversal(data):
    """
    Test for directory traversal vulnerabilities.

    Args:
        data (dict): Data containing URL and parameters.

    Returns:
        list: List of detected directory traversal vulnerabilities.
    """
    url = data['url']
    methods = ['GET', 'POST']
    payloads = [
        '../../../../etc/passwd', 
        '..\\..\\..\\..\\windows\\system32\\config\\SAM', 
        '/../../../../etc/passwd', 
        '/..\\..\\..\\..\\windows\\system32\\config\\SAM'
    ]

    vulnerabilities = []
    for method in methods:
        for payload in payloads:
            if method == 'GET':
                test_url = f"{url}{payload}"
                response = request_with_retry(test_url, method='GET')
            else:
                response = request_with_retry(url, method='POST', data={payload: ''})

            if response:
                if response.status_code == 200 and (
                    'root:' in response.text or 
                    re.search(r'etc/passwd|system32', response.text, re.IGNORECASE)
                ):
                    vulnerabilities.append({
                        'URL': test_url if method == 'GET' else url,
                        'Parameter': payload if method == 'POST' else '',
                        'Payload': payload,
                        'Response Code': response.status_code,
                        'Severity': 'High',
                        'Details': 'Directory traversal vulnerability found'
                    })

    return vulnerabilities if vulnerabilities else None

def test_sensitive_data_exposure(data):
    """
    Test for sensitive data exposure vulnerabilities.

    Args:
        data (dict): Data containing URL.

    Returns:
        list: List of detected sensitive data exposure vulnerabilities.
    """
    url = data['url']
    sensitive_patterns = [r'password', r'key', r'token']
    response = request_with_retry(url)
    if response and any(re.search(pattern, response.text, re.IGNORECASE) for pattern in sensitive_patterns):
        return [{
            'URL': url,
            'Parameter': '',
            'Payload': '',
            'Response Code': response.status_code,
            'Severity': 'Medium',
            'Details': 'Sensitive data exposure found'
        }]
    return None

def test_sql_injection(data):
    """
    Test for SQL injection vulnerabilities.

    Args:
        data (dict): Data containing URL and parameters.

    Returns:
        list: List of detected SQL injection vulnerabilities.
    """
    url = data['url']
    parameters = data.get('params', {})
    payloads = ["' OR '1'='1", '" OR "1"="1', "1' UNION SELECT NULL--"]

    # Test GET parameters
    for param in parameters:
        for payload in payloads:
            test_url = f"{url}?{param}={payload}"
            response = request_with_retry(test_url)
            if response and response.status_code == 500:
                return [{
                    'URL': test_url,
                    'Parameter': param,
                    'Payload': payload,
                    'Response Code': response.status_code,
                    'Severity': 'Critical',
                    'Details': 'SQL Injection vulnerability found'
                }]

    # Test POST parameters
    for param in parameters:
        for payload in payloads:
            response = request_with_retry(url, method='POST', data={param: payload})
            if response and response.status_code == 500:
                return [{
                    'URL': url,
                    'Parameter': param,
                    'Payload': payload,
                    'Response Code': response.status_code,
                    'Severity': 'Critical',
                    'Details': 'SQL Injection vulnerability found'
                }]

    return None

def test_xss(data):
    """
    Test for Cross-Site Scripting (XSS) vulnerabilities.

    Args:
        data (dict): Data containing URL and parameters.

    Returns:
        list: List of detected XSS vulnerabilities.
    """
    url = data['url']
    parameters = data.get('params', {})
    payloads = ['<script>alert(1)</script>', '"><img src="x" onerror="alert(1)">']

    # Test GET parameters
    for param in parameters:
        for payload in payloads:
            test_url = f"{url}?{param}={payload}"
            response = request_with_retry(test_url)
            if response and payload in response.text:
                return [{
                    'URL': test_url,
                    'Parameter': param,
                    'Payload': payload,
                    'Response Code': response.status_code,
                    'Severity': 'High',
                    'Details': 'XSS vulnerability found'
                }]

    # Test POST parameters
    for param in parameters:
        for payload in payloads:
            response = request_with_retry(url, method='POST', data={param: payload})
            if response and payload in response.text:
                return [{
                    'URL': url,
                    'Parameter': param,
                    'Payload': payload,
                    'Response Code': response.status_code,
                    'Severity': 'High',
                    'Details': 'XSS vulnerability found'
                }]

    return None

def test_bruteforce(data):
    """
    Test for brute force vulnerabilities by attempting common credentials.

    Args:
        data (dict): Data containing URL.

    Returns:
        list: List of detected brute force vulnerabilities.
    """
    url = data['url']
    payloads = ['admin', 'password', '123456']
    vulnerabilities = []

    for payload in payloads:
        response = request_with_retry(url, method='POST', data={'username': 'admin', 'password': payload})
        
        if response:
            if response.history and any(200 <= r.status_code < 300 for r in response.history):
                for r in response.history:
                    if re.search(r'(dashboard|home|profile|welcome)', r.url, re.IGNORECASE):
                        vulnerabilities.append({
                            'URL': url,
                            'Parameter': 'username/password',
                            'Payload': payload,
                            'Response Code': response.status_code,
                            'Severity': 'Critical',
                            'Details': 'Brute force vulnerability found - Login successful'
                        })
                        break
            elif response.status_code == 200 and 'Welcome' in response.text:
                vulnerabilities.append({
                    'URL': url,
                    'Parameter': 'username/password',
                    'Payload': payload,
                    'Response Code': response.status_code,
                    'Severity': 'Critical',
                    'Details': 'Brute force vulnerability found - Login successful'
                })
    
    return vulnerabilities if vulnerabilities else None

def test_file_inclusion(data):
    """
    Test for file inclusion vulnerabilities.

    Args:
        data (dict): Data containing URL.

    Returns:
        list: List of detected file inclusion vulnerabilities.
    """
    url = data['url']
    payloads = ['../../../../etc/passwd', '../../../../../var/www/html/index.php']
    vulnerabilities = []

    for payload in payloads:
        test_url = f"{url}?page={payload}"
        response = request_with_retry(test_url)
        if response and 'root:' in response.text:
            vulnerabilities.append({
                'URL': test_url,
                'Parameter': 'page',
                'Payload': payload,
                'Response Code': response.status_code,
                'Severity': 'High',
                'Details': 'File Inclusion vulnerability found'
            })

    return vulnerabilities if vulnerabilities else None

def test_csrf(data):
    """
    Test for Cross-Site Request Forgery (CSRF) vulnerabilities.

    Args:
        data (dict): Data containing URL.

    Returns:
        list: List of detected CSRF vulnerabilities.
    """
    url = data['url']
    payload = {'action': 'delete', 'id': '1'}
    response = request_with_retry(url, method='POST', data=payload)
    if response and response.status_code == 200:
        return [{
            'URL': url,
            'Parameter': '',
            'Payload': payload,
            'Response Code': response.status_code,
            'Severity': 'High',
            'Details': 'CSRF vulnerability potentially found'
        }]
    return None

def test_file_upload(data):
    """
    Test for file upload vulnerabilities.

    Args:
        data (dict): Data containing URL.

    Returns:
        list: List of detected file upload vulnerabilities.
    """
    url = data['url']
    files = {'file': ('test.txt', 'dummy content')}
    response = request_with_retry(url, method='POST', files=files)
    if response and response.status_code == 200 and 'success' in response.text.lower():
        return [{
            'URL': url,
            'Parameter': 'file',
            'Payload': 'file upload',
            'Response Code': response.status_code,
            'Severity': 'Critical',
            'Details': 'File upload vulnerability found'
        }]
    return None

# Main execution flow
def main():

    clear_screen()  # Clear the screen before starting
    """
    Main function to execute the security testing process.
    """
    console.print("""
       .---------       `---------.      `.-://::.``---  .----------------`    
   sddddddddd:      oddddddddd/    .+yddmmmmmdhsddd` +dddddddddddddddd:    
   :+smmdymmmd.    /mmhhmmmdo+-  `odmmmdho++oydmmmd` ommh++ymmmms++dmm:    
     -mmh.dmmmy`  .dmd.smmmd`    smmmmh-      .yddd` omms  ommmm:  hmm:    
     -mmh :mmmmo `hmm/ smmmd`   -mmmmd.        `---  /ss+  ommmm:  oss-    
     -mmh  +mmmm:smms  smmmd`   /mmmmh                     ommmm-          
     -mmh   ymmmdmmh`  smmmd`   -mmmmd.        .hs/-       ommmm-          
     .mmh   `hmmmmd.   smmmd`    smmmmh:`    `:hmmm/       ommmm-          
   :osmmdoo. -dmmm/  +ohmmmmoo-  `ommmmmdysoyhmmmd/     -oohmmmmsoo`       
   ommmmmmm:  /mms   dmmmmmmmm/    .+ydmmmmmmmdy/`      /mmmmmmmmmd`       
   .-------`   --`   ---------`      ``.-::-..`         `---------- 
    <=- Majalengka Cyber Tester -=>
    """)
    target_url = input("Masukan URL: ").strip()  # Ganti dengan URL target
    console.print(f"[bold cyan]Menyiapkan Pengujian untuk: {target_url}[/bold cyan]")

    # Gather information
    info = gather_info(target_url)
    console.print(f"[bold green]Informasi Target Dikumpulkan[/bold green]")

    # Crawl website
    crawled_data = crawl_website(target_url)
    console.print(f"[bold green]Data Dirayapi[/bold green]")

    # Test vulnerabilities
    vulnerabilities = test_vulnerabilities(crawled_data)
    console.print(f"[bold green]Pengujian Selesai[/bold green]")

    # Generate report
    generate_html_report(vulnerabilities, info, crawled_data)
    console.print("[bold green]Laporan HTML selesai dibuat![/bold green]")

if __name__ == "__main__":
    main()
